{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nhezn-z4J1Rvxk07dMsUv6iN-io0__G_",
      "authorship_tag": "ABX9TyPEJ6mXSLzJK7DfalBhvfOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8794d9c323c94c29b4326aba7b1120c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9453b75146f1466a92b5133785912d55",
              "IPY_MODEL_306668f79edc47aebff41e7fb78bc0d2",
              "IPY_MODEL_731897ea14cc495a9393360110cc54dd"
            ],
            "layout": "IPY_MODEL_a797759e802543738b044742a3136033"
          }
        },
        "9453b75146f1466a92b5133785912d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f70ef158fa7042e8b81add504d8a57d7",
            "placeholder": "​",
            "style": "IPY_MODEL_bd737cfc58b44d80af44cbf32bf425c3",
            "value": "Transcribing: 100%"
          }
        },
        "306668f79edc47aebff41e7fb78bc0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b036124c2f246f79646ef13cf76298f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfeddedd067c411895edecea99f4af4d",
            "value": 1
          }
        },
        "731897ea14cc495a9393360110cc54dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c5ba90b92b44d55b872a6a57b2ac8ce",
            "placeholder": "​",
            "style": "IPY_MODEL_6779cace6b004439bfe61da1a8e3e994",
            "value": " 1/1 [00:02&lt;00:00,  2.85s/it]"
          }
        },
        "a797759e802543738b044742a3136033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f70ef158fa7042e8b81add504d8a57d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd737cfc58b44d80af44cbf32bf425c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b036124c2f246f79646ef13cf76298f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfeddedd067c411895edecea99f4af4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c5ba90b92b44d55b872a6a57b2ac8ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6779cace6b004439bfe61da1a8e3e994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nukaraju2003/Natural-Language-Processing/blob/main/video_transcription_ands_evaluation_using_openai_api_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CBvzeXzmATk",
        "outputId": "54a6109a-a079-4d67-e934-e8eaac5d7eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install imageio==2.4.1\n",
        "!pip install imageio-ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv8DdUmjmGS1",
        "outputId": "14a3b309-9943-441e-f84b-7addcf2ec3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from imageio==2.4.1) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from imageio==2.4.1) (8.4.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303886 sha256=380b61b84f2c77acb6c42f69dd18c733630be60152643398d1d7befd60aed88b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/44/b7/2e7cc9c5fe4a893b9cc83a010d4410557bedf6cf3b5829f497\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed imageio-2.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZXw7SnxmJ50",
        "outputId": "799d4feb-0822-4398-c4ec-3073b48d97dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.9/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.9/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.9/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.9/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "imageio.plugins.ffmpeg.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "RboTOrg7m90s",
        "outputId": "95c1a23f-2691-4c21-9243-ca1197febb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-823aaddcb2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/imageio/plugins/ffmpeg.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(directory, force_download)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;34m\"imageio.ffmpeg.download() has been deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"Use 'pip install imageio-ffmpeg' instead.'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: imageio.ffmpeg.download() has been deprecated. Use 'pip install imageio-ffmpeg' instead.'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import moviepy.editor as mp\n",
        "clip = mp.VideoFileClip(\"/content/drive/MyDrive/325706_28-02-2022_VID_20220228_112727_337.mp4\")\n",
        "clip.audio.write_audiofile(\"theaudio.mp3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q0U0Xlhl8pW",
        "outputId": "0edf1907-fc42-490d-9823-2988d05a117c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Writing audio in theaudio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1939/1939 [00:02<00:00, 744.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeW0_cdvc5ei",
        "outputId": "afdf7540-2785-43e1-cc8e-73bc9dc1ff90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2023-03-15 09:36:11 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
            "[NeMo W 2023-03-15 09:36:12 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2023-03-15 09:36:14 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2023-03-15 09:36:14 nemo_logging:349] /usr/local/lib/python3.9/dist-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
            "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
            "    \n",
            "[NeMo W 2023-03-15 09:36:15 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2023-03-15 09:36:15 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2023-03-15 09:36:15 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2023-03-15 09:36:15 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
            "[NeMo W 2023-03-15 09:36:15 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-03-15 09:36:15 cloud:66] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_conformer_transducer_large/versions/1.10.0/files/stt_en_conformer_transducer_large.nemo to /root/.cache/torch/NeMo/NeMo_1.15.0/stt_en_conformer_transducer_large/1919c44e1281bbcba59356c6091a6b94/stt_en_conformer_transducer_large.nemo\n",
            "[NeMo I 2023-03-15 09:36:31 common:913] Instantiating model from pre-trained checkpoint\n",
            "[NeMo I 2023-03-15 09:36:34 mixins:170] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2023-03-15 09:36:34 modelPT:156] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath:\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket1/tarred_audio_manifest.json\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket2/tarred_audio_manifest.json\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket3/tarred_audio_manifest.json\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket4/tarred_audio_manifest.json\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket5/tarred_audio_manifest.json\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket6/tarred_audio_manifest.json\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket7/tarred_audio_manifest.json\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket8/tarred_audio_manifest.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 1\n",
            "    shuffle: true\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    use_start_end_token: false\n",
            "    trim_silence: false\n",
            "    max_duration: 20.0\n",
            "    min_duration: 0.1\n",
            "    is_tarred: true\n",
            "    tarred_audio_filepaths:\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket1/audio__OP_0..8191_CL_.tar\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket2/audio__OP_0..8191_CL_.tar\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket3/audio__OP_0..8191_CL_.tar\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket4/audio__OP_0..8191_CL_.tar\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket5/audio__OP_0..8191_CL_.tar\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket6/audio__OP_0..8191_CL_.tar\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket7/audio__OP_0..8191_CL_.tar\n",
            "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket8/audio__OP_0..8191_CL_.tar\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size:\n",
            "    - 88\n",
            "    - 80\n",
            "    - 72\n",
            "    - 64\n",
            "    - 56\n",
            "    - 48\n",
            "    - 40\n",
            "    - 32\n",
            "    \n",
            "[NeMo W 2023-03-15 09:36:34 modelPT:163] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    use_start_end_token: false\n",
            "    \n",
            "[NeMo W 2023-03-15 09:36:34 modelPT:169] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath:\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-other.json\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-dev-other.json\n",
            "    - /data/ASR/LibriSpeech/librispeech_withsp2/manifests/librivox-test-clean.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    use_start_end_token: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-03-15 09:36:34 features:267] PADDING: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2023-03-15 09:36:35 nemo_logging:349] /usr/local/lib/python3.9/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2023-03-15 09:36:36 rnnt_models:207] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2023-03-15 09:36:45 save_restore_connector:243] Model EncDecRNNTBPEModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.15.0/stt_en_conformer_transducer_large/1919c44e1281bbcba59356c6091a6b94/stt_en_conformer_transducer_large.nemo.\n"
          ]
        }
      ],
      "source": [
        "BRANCH = 'r1.15.0'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[asr]\n",
        "! wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/nemo_text_processing/install_pynini.sh\n",
        "! bash install_pynini.sh\n",
        "import nemo\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name = 'stt_en_conformer_transducer_large').cuda()\n",
        "else:\n",
        "  asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name = 'stt_en_conformer_transducer_large')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub.utils import mediainfo\n",
        "info = mediainfo(\"/content/theaudio.mp3\")\n",
        "# print(info['sample_rate'])\n",
        "\n",
        "print(info['channels'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8sbEOK4job9",
        "outputId": "8ad84df3-e3fd-45e6-a265-f3f63b73cc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "y, sr = librosa.load('/content/theaudio.mp3')\n",
        "y_mono = librosa.to_mono(y)"
      ],
      "metadata": {
        "id": "GONm9ygvpVA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from librosa import output\n",
        "librosa.output.write_wav('file_trim_5s.wav', y_mono, sr)"
      ],
      "metadata": {
        "id": "Y_MhyUnXpQ4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "filename = '/content/theaudio.mp3'\n",
        "try:\n",
        "    sound = AudioSegment.from_file(filename, \"mp3\")\n",
        "except:\n",
        "    sound = AudioSegment.from_file(filename, format=\"mp4\")\n",
        "sound = sound.set_channels(1)\n",
        "sound.export(\"monoaudio.wav\", format=\"wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2wiO9Jdong4",
        "outputId": "6c93f271-552e-4998-8dd5-444032daba57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='monoaudio.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = asr_model.transcribe(['/content/monoaudio.wav'])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8794d9c323c94c29b4326aba7b1120c3",
            "9453b75146f1466a92b5133785912d55",
            "306668f79edc47aebff41e7fb78bc0d2",
            "731897ea14cc495a9393360110cc54dd",
            "a797759e802543738b044742a3136033",
            "f70ef158fa7042e8b81add504d8a57d7",
            "bd737cfc58b44d80af44cbf32bf425c3",
            "5b036124c2f246f79646ef13cf76298f",
            "dfeddedd067c411895edecea99f4af4d",
            "9c5ba90b92b44d55b872a6a57b2ac8ce",
            "6779cace6b004439bfe61da1a8e3e994"
          ]
        },
        "id": "3_mDYRwUnnaS",
        "outputId": "593b793e-7744-4205-fd73-facff196ca51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8794d9c323c94c29b4326aba7b1120c3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n82e-1-Brteu",
        "outputId": "206cc5bd-420a-46b2-cc99-33fa2e3ecbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"hi my name is julie saha i was born and raised in m p japan i have completed graduation in commerce in the year two thousand sixteen with correspondence we are a family of five my mother in law my husband my two kids and i i uh i have overall eight and a half years of work experience for the international b p o i have worked in inbound and outbound customer care and semi technical process in my leisure time i like to spend most of my time reading books listening to music travelling and of course and with my kids about uh talking about my strength i would say i'm self motivated i do not need someone else to push me to achieve my goals and dreams and about weakness i would say um i look for perfection i completely understand it is humanly not always possible to be perfect hence i'm working on uh my weakness to make sure that i figure out a way to get things done and in a better way even if it is not perfect and um yes uh that's mostly about me thank you so much for giving me this opportunity to talk about myself and introduce myself to you all hope to hear from you soon thank you you have a good day bye\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNRkXgCSxfkD",
        "outputId": "59f82fc3-7c65-4c3c-e59a-7bbe893332d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (3.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai  \n",
        "openai.api_key = \"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\"\n",
        "ques = \"Rate the following answer on a scale of 10 for the question Tell us something about yourself in an HR Interview\"\n",
        "prompt = f\"For the question, \\\"{ques}\\\", give a score out of 10 each for Relevance, Clarity,Clarity, Confidence, Enthusiasm, Unique qualities,Professionalism for the following answer with a proper explanation for each: \\\"{txt}\\\"\"\n",
        "model_engine = \"gpt-3.5-turbo\"\n",
        "response = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ])\n",
        "\n",
        "message = response.choices[0]['message']\n",
        "print(\"{}: {}\".format(message['role'], message['content']))\n"
      ],
      "metadata": {
        "id": "aUemjMGAxjr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab20e8a-cdc5-4255-cdb8-2b0360cba71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: Here's a score out of 10 for each criterion:\n",
            "\n",
            "1. Relevance - 8/10 - The answer is mostly relevant and addresses the key criteria of a typical HR interview question that asks for a brief introduction of oneself. However, the answer could have focused on more relevant details related to the job or position being applied for.\n",
            "2. Clarity - 7/10 - The answer is not very clear in some parts, as there are some gaps and repetitions in the speaker's communication that tend to confuse the listener. The response included some long sentences with multiple ideas, making it difficult to follow the speaker's thoughts.\n",
            "3. Confidence - 8/10 - The answer shows a considerable amount of confidence, as the candidate maintains a steady demeanor throughout the response. They deliver their statements in a clear and coherent manner, indicating self-assurance.\n",
            "4. Enthusiasm - 8/10 - Although the answer does not show an over-enthusiastic approach, the candidate's tone sounds lively, and they express their views in a positive and engaging way, making it interesting for the interviewer to listen.\n",
            "5. Unique Qualities - 6/10 - The response highlights a few unique qualities, such as self-motivation and a desire to improve their perfectionist tendencies. However, the answer could have included more examples of specific and unique skills or experiences, as it appears basic and common.\n",
            "6. Professionalism - 8/10 - The answer is generally professional and appropriate for an HR interview. The candidate maintains a sense of decorum and avoids any controversial statement or sensitive topic, making a good impression on the interviewer.\n",
            "\n",
            "Overall, the response deserves a 7.5 out of 10 since it presents some good points but also has some minor flaws that could be addressed to improve its effectiveness.\n"
          ]
        }
      ]
    }
  ]
}