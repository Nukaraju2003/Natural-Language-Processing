{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nukaraju2003/Natural-Language-Processing/blob/main/NLP2assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://s3.ap-south-1.amazonaws.com/acsess/images/96bb925a-153c-4ff5-bb1f-5f85ba048b2c)"
      ],
      "metadata": {
        "id": "JTzHrwHgm04k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes implementation\n",
        "We shall undertand Python object oreinted implementation of this algorithm.\n",
        "\n",
        "Example case: we want to determine gender from name."
      ],
      "metadata": {
        "id": "9hGKT8ndm8_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('names')\n",
        "from nltk.corpus import names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggvH_eFwowdY",
        "outputId": "3d6d5213-726a-44f3-9879-98af164bf304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Design\n",
        "Here we would plan features for gender identification\n",
        "\n",
        "### Possible features\n",
        "\n",
        "* ending character"
      ],
      "metadata": {
        "id": "lWaVcDUxqQcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(word):\n",
        "  \"\"\"\n",
        "  This function will take a word and return a dictionary of gender features\n",
        "  {'feature_name''feature_value}\n",
        "  \"\"\"\n",
        "  word = word.strip().lower()\n",
        "  return {'last_letter':word[-1]}"
      ],
      "metadata": {
        "id": "PIY_OBD7rs2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(gender_features(name), 'female') for name in names.words(\"female.txt\")] \\\n",
        "  + [(gender_features(name), 'male') for name in names.words(\"male.txt\")]"
      ],
      "metadata": {
        "id": "jBEujqd2pEcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "KhZqGLUlpjbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(data)\n",
        "import math\n",
        "t_n = math.ceil(0.9*n)\n",
        "train_data, test_data = data[:t_n], data[t_n:]"
      ],
      "metadata": {
        "id": "s-6-F2UUoWCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data), train_data[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8PhExg0rOSN",
        "outputId": "9073bf32-4907-4406-b0dd-fd669d889b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7150 [({'last_letter': 'l'}, 'male'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'y'}, 'male'), ({'last_letter': 'd'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'e'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'e'}, 'male')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probability add-alpha implementation\n",
        "Below class will implement converting counts (or frequencies) across various values into a probability distribution with add alpha smoothing"
      ],
      "metadata": {
        "id": "ftKaP1gRAq-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "_NINF = float('-1e300')\n",
        "\n",
        "class ProbDist:\n",
        "  def __init__(self, freqdist, alpha=0.5, bins=None):\n",
        "    self._alpha = alpha\n",
        "    self._freqdist = freqdist\n",
        "    n = sum(freqdist.values()) # find total value across all bins\n",
        "    self._bins = len(freqdist) if bins is None else bins\n",
        "    self._divisor = n + self._bins*self._alpha\n",
        "\n",
        "  def prob(self, sample):\n",
        "    c = self._freqdist.get(sample, 0) + self._alpha\n",
        "    return c/self._divisor\n",
        "\n",
        "  def logprob(self, sample):\n",
        "    p = self.prob(sample)\n",
        "    return math.log(p, 2) if p!=0 else _NINF\n",
        "\n",
        "  def samples(self):\n",
        "    return self._freqdist.keys()"
      ],
      "metadata": {
        "id": "zTlOfiaTyTj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log Softmax\n",
        "(Optional)\n",
        "This is copied from NLTK as is. It tries to implement log softmax\n",
        "\n",
        "we have log probabilities already and not probabilities\n",
        "\n",
        "If probabilities are there then softmax = e^x/SUM(e^xi) for all i\n",
        "\n",
        "For log softmax we need\n",
        "logprob(x) - log of sum of all probs\n",
        "\n",
        "But we have log(x1), log(x2) .... log(xn) the n logprobs for n labels\n",
        "\n",
        "we need to calculate log(x1+x2+...+xn)\n",
        "\n",
        "Below is an implementation of the same."
      ],
      "metadata": {
        "id": "rRdrlP0GA5g6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# need to add two logs\n",
        "_ADD_LOGS_MAX_DIFF = math.log(1e-30, 2)\n",
        "def add_logs(logx, logy):\n",
        "  \"\"\"\n",
        "  Ideally log(x+y) = log(2**logx + 2**logy)\n",
        "  as we already have logx and logy\n",
        "  below implementation takes care of overflow errors\n",
        "  (copied from NLTK source code)\n",
        "\n",
        "  NOTE: These work when all logprobs are less than 1\n",
        "  \n",
        "  \"\"\"\n",
        "  if (logx < logy + _ADD_LOGS_MAX_DIFF):\n",
        "    return logy\n",
        "  elif (logy < logx + _ADD_LOGS_MAX_DIFF):\n",
        "    return logx\n",
        "  \n",
        "  base = min(logx, logy)\n",
        "  return base + math.log(2**(logx-base) + 2**(logy-base), 2)\n",
        "\n",
        "from functools import reduce\n",
        "\n",
        "def sum_logs(logs):\n",
        "  return reduce(add_logs, logs[1:], logs[0]) if len(logs)!=0 else _NINF\n",
        "\n",
        "class LogSoftmax:\n",
        "  def __init__(self, prob_dict):\n",
        "    self._prob_dict = prob_dict\n",
        "    assert len(prob_dict)>0, \"There must be at least one class\"\n",
        "\n",
        "    value_sum = sum_logs(list(self._prob_dict.values()))\n",
        "\n",
        "    if value_sum <= _NINF:\n",
        "      pass #todo: return equal prob for each class\n",
        "    else:\n",
        "      for (x,p) in self._prob_dict.items():\n",
        "        self._prob_dict[x] -= value_sum\n",
        "\n",
        "    self._max = max((value, label) for (label, value) in self._prob_dict.items())\n",
        "\n",
        "\n",
        "  def probs(self):\n",
        "    return dict(sorted(self._prob_dict.items(), key=lambda item: -item[1]))\n",
        "\n",
        "  def max(self):\n",
        "    return self._max[1]"
      ],
      "metadata": {
        "id": "fKTrnBuzyTEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kntap_bdRpqu"
      },
      "outputs": [],
      "source": [
        "from nltk.tbl import feature\n",
        "class NaiveBayesClassifier:\n",
        "  \"\"\"\n",
        "  Implements a Naive Bayes Classifier\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, training_dataset, alpha=0.5):\n",
        "    \"\"\"\n",
        "    trains a naive bayes classifier on the. training dataset\n",
        "\n",
        "    the training dataset must be a list of [(feature dict, class label)]\n",
        "    where feature dict is a dict of featur names and their corresponding\n",
        "    values for every training example.\n",
        "    \"\"\"\n",
        "    # do some validation if the format is right\n",
        "    # now train if valid\n",
        "    self._train(training_dataset, alpha)\n",
        "\n",
        "  def _train(self, training_dataset, alpha):\n",
        "    \"\"\"\n",
        "    Train NB classifier and return\n",
        "    - log prior class probabilities\n",
        "    - log likelihoods for all features in the vocabulary\n",
        "    - vocabulary\n",
        "    \"\"\"\n",
        "    feature_freqdist = {}\n",
        "    feature_values = {}\n",
        "    feature_names = set()\n",
        "    class_freqdist = {}\n",
        "\n",
        "    for featureset, label in training_dataset:\n",
        "      class_freqdist[label] = class_freqdist.get(label, 0)+1 #P(c)\n",
        "\n",
        "      for fname, fval in featureset.items():\n",
        "        # calculate P(fi|c)\n",
        "        # we need to find counts for each feature value for each class\n",
        "        feature_freqdist[(label, fname)] = feature_freqdist.get((label, fname), {})\n",
        "        feature_freqdist[(label, fname)][fval] = feature_freqdist[(label, fname)].get(fval, 0) + 1\n",
        "\n",
        "        # we need to find vocabulary for each feature\n",
        "        feature_values[fname] = feature_values.get(fname, set())\n",
        "        feature_values[fname].add(fval)\n",
        "\n",
        "        # we need to get list of all features across all training example\n",
        "        feature_names.add(fname)\n",
        "\n",
        "    #print(feature_freqdist)\n",
        "    #print(feature_values)\n",
        "    #print(feature_names)\n",
        "    #print(class_freqdist)\n",
        "\n",
        "    # Now that we have our counts, we need to calculate the probability\n",
        "    # distributions, with add-alpha smoothing\n",
        "    \n",
        "    # handle missing feature values in a class\n",
        "    # this is optional and may not be needed\n",
        "    # so commented for now\n",
        "    # for label in class_freqdist:\n",
        "    #   num_samples = class_freqdist[label]\n",
        "    #   for fname in feature_names:\n",
        "    #     count = sum(feature_freqdist[(label, fname)].values())\n",
        "    #     if num_samples > count: #case where in my input data set certain samples donot have certain features\n",
        "    #       feature_freqdist[(label, fname)][None] = num_samples - count\n",
        "    #       feature_values[fname].add(None)\n",
        "\n",
        "    # do the probabilities\n",
        "    self._class_probdist = ProbDist(class_freqdist)\n",
        "    self._feature_probdist = {}\n",
        "    for ((label, fname), freqdist) in feature_freqdist.items():\n",
        "      self._feature_probdist[(label, fname)] = ProbDist(freqdist, bins=len(feature_values[fname]))\n",
        "    self._labels = list(self._class_probdist.samples())\n",
        "\n",
        "    print(self._class_probdist)\n",
        "    print(self._feature_probdist)\n",
        "    print(self._labels)\n",
        "\n",
        "\n",
        "  def prob_classify(self, featureset):\n",
        "    \"\"\"\n",
        "    Gives the argmax or the class predicted or most probable for the given \n",
        "    feature set\n",
        "    \"\"\"\n",
        "    # remove unknown features\n",
        "    features = {}\n",
        "    for fname in featureset.keys():\n",
        "      for label in self._labels:\n",
        "        if (label, fname) in self._feature_probdist:\n",
        "          features[fname] = featureset[fname]\n",
        "          break\n",
        "\n",
        "    logprob = {} #for each class I need to calculate these logprob\n",
        "    for label in self._labels:\n",
        "      logprob[label] = self._class_probdist.logprob(label) #P(c)\n",
        "      for (fname, fval) in features.items():\n",
        "        if (label, fname) in self._feature_probdist:\n",
        "          logprob[label] += self._feature_probdist[(label, fname)].logprob(fval)\n",
        "        else: #this case should never arise if we are generating the prob dist ourselves\n",
        "          logprob[label] += _NINF\n",
        "\n",
        "    # need to convert this into a probability that sums to 1\n",
        "    # log softmax\n",
        "    #return LogSoftmax(logprob)\n",
        "    return logprob\n",
        "    \n",
        "  def classify(self, featureset):\n",
        "    p = self.prob_classify(featureset)\n",
        "    print(p)\n",
        "    l = sorted(p.items(), key=lambda x:-x[1])\n",
        "    \n",
        "    #return self.prob_classify(featureset).max()\n",
        "    return l[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nbc = NaiveBayesClassifier(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyCtoAYgxU5C",
        "outputId": "44d9835f-9491-4d4c-80a0-58edbc3d507b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.ProbDist object at 0x7ff15e6ad310>\n",
            "{('male', 'last_letter'): <__main__.ProbDist object at 0x7ff15e6adb90>, ('female', 'last_letter'): <__main__.ProbDist object at 0x7ff15e6ad1d0>}\n",
            "['male', 'female']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nbc.classify(gender_features(\"Neo\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "h9CeoqeexZst",
        "outputId": "3be5e386-847f-4b97-cf05-d81290551277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'male': -5.625622858137834, 'female': -7.877015771643056}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'male'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(data):\n",
        "  c = 0\n",
        "  for d, label in data:\n",
        "    c+=(nbc.classify(d)==label)\n",
        "  return c/len(data)"
      ],
      "metadata": {
        "id": "b_snQ82i8elI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfqhTP3X9Mo5",
        "outputId": "1467e59d-8c91-426e-a103-baf54b701251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7707808564231738"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5rIaEHc9N7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}